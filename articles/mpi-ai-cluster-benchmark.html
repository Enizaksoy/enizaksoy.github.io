<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Comprehensive guide to MPI collective operations benchmarking for AI training clusters - Understanding Allreduce, network optimization, and performance analysis">
    <meta name="keywords" content="MPI, Allreduce, AI Training, RDMA, NCCL, Distributed Training, GPU Cluster, Network Performance">
    <meta name="author" content="Eniz Aksoy, CCIE #23970">
    <title>MPI Collective Operations for AI Training - Complete Technical Guide | Eniz Aksoy</title>
    <style>
        :root {
            --primary: #2563eb;
            --secondary: #1e40af;
            --accent: #f59e0b;
            --text: #1f2937;
            --text-light: #6b7280;
            --bg: #ffffff;
            --bg-alt: #f8fafc;
            --bg-code: #0f172a;
            --border: #e2e8f0;
            --success: #10b981;
            --warning: #f59e0b;
            --info: #06b6d4;
        }

        * { margin: 0; padding: 0; box-sizing: border-box; }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, sans-serif;
            line-height: 1.8;
            color: var(--text);
            background: var(--bg);
            font-size: 17px;
        }

        /* Hero */
        .hero {
            background: linear-gradient(135deg, #0f172a 0%, #1e40af 50%, #2563eb 100%);
            color: white;
            padding: 100px 20px 80px;
            text-align: center;
            position: relative;
        }

        .hero::after {
            content: '';
            position: absolute;
            bottom: 0;
            left: 0;
            right: 0;
            height: 100px;
            background: linear-gradient(to bottom, transparent, var(--bg));
        }

        .hero h1 {
            font-size: 2.8rem;
            margin-bottom: 15px;
            font-weight: 700;
        }

        .hero .subtitle {
            font-size: 1.3rem;
            opacity: 0.9;
            margin-bottom: 25px;
            max-width: 700px;
            margin-left: auto;
            margin-right: auto;
        }

        .hero .meta {
            font-size: 0.95rem;
            opacity: 0.8;
        }

        .badges {
            display: flex;
            justify-content: center;
            gap: 12px;
            flex-wrap: wrap;
            margin: 25px 0;
        }

        .badge {
            padding: 8px 18px;
            border-radius: 25px;
            font-size: 0.9rem;
            font-weight: 600;
            background: rgba(255,255,255,0.15);
            backdrop-filter: blur(10px);
            border: 1px solid rgba(255,255,255,0.2);
        }

        /* Navigation */
        .article-nav {
            background: var(--bg-alt);
            border-bottom: 1px solid var(--border);
            padding: 20px;
            position: sticky;
            top: 0;
            z-index: 100;
        }

        .nav-container {
            max-width: 1100px;
            margin: 0 auto;
            display: flex;
            justify-content: space-between;
            align-items: center;
        }

        .back-link {
            color: var(--primary);
            text-decoration: none;
            font-weight: 500;
            display: flex;
            align-items: center;
            gap: 8px;
        }

        .toc-dropdown {
            position: relative;
        }

        .toc-btn {
            background: var(--primary);
            color: white;
            border: none;
            padding: 10px 20px;
            border-radius: 6px;
            cursor: pointer;
            font-weight: 500;
        }

        /* Main Content */
        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 60px 20px;
        }

        /* Typography */
        h2 {
            font-size: 2rem;
            color: var(--secondary);
            margin: 60px 0 25px;
            padding-bottom: 15px;
            border-bottom: 3px solid var(--primary);
            font-weight: 700;
        }

        h3 {
            font-size: 1.5rem;
            color: var(--text);
            margin: 40px 0 20px;
            font-weight: 600;
        }

        h4 {
            font-size: 1.2rem;
            color: var(--text);
            margin: 30px 0 15px;
            font-weight: 600;
        }

        p {
            margin-bottom: 20px;
            color: var(--text);
        }

        ul, ol {
            margin: 0 0 25px 25px;
        }

        li {
            margin-bottom: 10px;
        }

        strong {
            color: var(--secondary);
        }

        /* Code */
        pre {
            background: var(--bg-code);
            color: #e2e8f0;
            padding: 25px;
            border-radius: 10px;
            overflow-x: auto;
            margin: 25px 0;
            font-family: 'JetBrains Mono', 'Fira Code', Consolas, monospace;
            font-size: 0.9rem;
            line-height: 1.6;
            border: 1px solid #1e293b;
        }

        code {
            font-family: 'JetBrains Mono', 'Fira Code', Consolas, monospace;
            background: var(--bg-alt);
            padding: 3px 8px;
            border-radius: 4px;
            font-size: 0.9em;
            color: var(--secondary);
        }

        pre code {
            background: none;
            padding: 0;
            color: #e2e8f0;
        }

        .code-comment { color: #6b7280; }
        .code-keyword { color: #f472b6; }
        .code-string { color: #34d399; }
        .code-number { color: #fbbf24; }
        .code-highlight { color: #fbbf24; font-weight: bold; }

        /* Tables */
        .table-wrapper {
            overflow-x: auto;
            margin: 25px 0;
            border-radius: 10px;
            border: 1px solid var(--border);
        }

        table {
            width: 100%;
            border-collapse: collapse;
            font-size: 0.95rem;
        }

        th, td {
            padding: 15px 18px;
            text-align: left;
            border-bottom: 1px solid var(--border);
        }

        th {
            background: var(--primary);
            color: white;
            font-weight: 600;
            white-space: nowrap;
        }

        tr:nth-child(even) { background: var(--bg-alt); }
        tr:hover { background: #e0e7ff; }

        /* Info Boxes */
        .info-box {
            padding: 25px;
            border-radius: 10px;
            margin: 30px 0;
            border-left: 5px solid;
        }

        .info-box.concept {
            background: #eff6ff;
            border-color: var(--primary);
        }

        .info-box.important {
            background: #fef3c7;
            border-color: var(--accent);
        }

        .info-box.success {
            background: #ecfdf5;
            border-color: var(--success);
        }

        .info-box.technical {
            background: #f0fdfa;
            border-color: var(--info);
        }

        .info-box h4 {
            margin-top: 0;
            margin-bottom: 15px;
            display: flex;
            align-items: center;
            gap: 10px;
        }

        /* Diagrams */
        .diagram {
            background: var(--bg-code);
            color: #e2e8f0;
            padding: 30px;
            border-radius: 10px;
            font-family: 'JetBrains Mono', Consolas, monospace;
            font-size: 0.85rem;
            line-height: 1.4;
            overflow-x: auto;
            white-space: pre;
            margin: 30px 0;
            border: 1px solid #1e293b;
        }

        .diagram-caption {
            text-align: center;
            font-style: italic;
            color: var(--text-light);
            margin-top: -20px;
            margin-bottom: 30px;
        }

        /* Stats Grid */
        .stats-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 20px;
            margin: 30px 0;
        }

        .stat-card {
            background: linear-gradient(135deg, var(--bg-alt), white);
            padding: 25px;
            border-radius: 12px;
            text-align: center;
            border: 1px solid var(--border);
            transition: transform 0.2s, box-shadow 0.2s;
        }

        .stat-card:hover {
            transform: translateY(-3px);
            box-shadow: 0 10px 30px rgba(0,0,0,0.1);
        }

        .stat-card .value {
            font-size: 2.2rem;
            font-weight: 700;
            color: var(--primary);
            display: block;
        }

        .stat-card .label {
            color: var(--text-light);
            font-size: 0.9rem;
            margin-top: 5px;
        }

        /* Key Takeaways */
        .key-takeaway {
            background: linear-gradient(135deg, #1e40af, #2563eb);
            color: white;
            padding: 30px;
            border-radius: 12px;
            margin: 40px 0;
        }

        .key-takeaway h4 {
            color: white;
            margin-top: 0;
        }

        .key-takeaway ul {
            margin-bottom: 0;
        }

        .key-takeaway li {
            opacity: 0.95;
        }

        /* Author Section */
        .author-section {
            background: linear-gradient(135deg, var(--bg-alt) 0%, #e0e7ff 100%);
            padding: 40px;
            border-radius: 15px;
            margin-top: 60px;
            display: flex;
            align-items: center;
            gap: 30px;
        }

        .author-info h3 {
            margin: 0 0 5px 0;
            color: var(--secondary);
        }

        .author-info .title {
            color: var(--text-light);
            margin-bottom: 15px;
        }

        .author-links {
            display: flex;
            gap: 12px;
            flex-wrap: wrap;
        }

        .author-links a {
            padding: 10px 20px;
            background: var(--primary);
            color: white;
            text-decoration: none;
            border-radius: 6px;
            font-weight: 500;
            transition: background 0.2s;
        }

        .author-links a:hover {
            background: var(--secondary);
        }

        /* Footer */
        footer {
            background: var(--bg-code);
            color: #94a3b8;
            text-align: center;
            padding: 40px 20px;
            margin-top: 60px;
        }

        footer a { color: var(--info); }

        /* Responsive */
        @media (max-width: 768px) {
            .hero h1 { font-size: 2rem; }
            .hero .subtitle { font-size: 1.1rem; }
            h2 { font-size: 1.6rem; }
            h3 { font-size: 1.3rem; }
            .author-section { flex-direction: column; text-align: center; }
            .stat-card .value { font-size: 1.8rem; }
        }
    </style>
</head>
<body>

<!-- Hero Section -->
<header class="hero">
    <h1>MPI Collective Operations for AI Training</h1>
    <p class="subtitle">A comprehensive guide to understanding, benchmarking, and optimizing distributed AI training communications</p>
    <div class="badges">
        <span class="badge">MPI / NCCL</span>
        <span class="badge">Distributed Training</span>
        <span class="badge">RDMA / RoCEv2</span>
        <span class="badge">Performance Analysis</span>
    </div>
    <p class="meta">By Eniz Aksoy, CCIE #23970 | January 2026 | 25 min read</p>
</header>

<!-- Navigation -->
<nav class="article-nav">
    <div class="nav-container">
        <a href="../index.html" class="back-link">&larr; Back to Portfolio</a>
        <span style="color: var(--text-light);">AI/ML Infrastructure Series</span>
    </div>
</nav>

<!-- Main Content -->
<main class="container">

    <!-- Executive Summary -->
    <section>
        <h2>Executive Summary</h2>
        <p>In the era of large language models (LLMs) and distributed AI training, understanding network communication patterns is crucial for building high-performance GPU clusters. This article provides an in-depth analysis of MPI collective operationsâ€”the backbone of distributed training frameworks like PyTorch Distributed, Horovod, and NVIDIA NCCL.</p>

        <p>Through extensive benchmarking on an 8-node RDMA cluster, I demonstrate how network architecture decisions directly impact training throughput, and provide practical guidance for network engineers designing AI infrastructure.</p>

        <div class="stats-grid">
            <div class="stat-card">
                <span class="value">38.9ms</span>
                <span class="label">4MB Allreduce Latency</span>
            </div>
            <div class="stat-card">
                <span class="value">64.9Î¼s</span>
                <span class="label">1KB Allreduce Latency</span>
            </div>
            <div class="stat-card">
                <span class="value">8</span>
                <span class="label">Node Cluster</span>
            </div>
            <div class="stat-card">
                <span class="value">25Gbps</span>
                <span class="label">RoCEv2 Links</span>
            </div>
        </div>
    </section>

    <!-- Why This Matters -->
    <section>
        <h2>Why Network Engineers Must Understand MPI</h2>

        <p>Traditional network engineering focuses on throughput, latency, and packet loss. AI/ML infrastructure introduces a new dimension: <strong>collective operation efficiency</strong>. A poorly designed network that delivers adequate point-to-point performance may catastrophically underperform for distributed training workloads.</p>

        <h3>The Scale of Modern AI Training</h3>
        <p>Consider training GPT-4 class models:</p>
        <ul>
            <li><strong>1.8 trillion parameters</strong> spread across thousands of GPUs</li>
            <li><strong>Every training step</strong> requires synchronizing gradients across all GPUs</li>
            <li><strong>Hundreds of terabytes</strong> of data exchanged per hour</li>
            <li><strong>Network becomes the bottleneck</strong> when GPU compute is maximized</li>
        </ul>

        <div class="info-box important">
            <h4>âš ï¸ Critical Insight</h4>
            <p>In distributed training, GPUs spend significant time waiting for network operations to complete. NVIDIA reports that <strong>up to 50% of training time</strong> can be spent on communication in poorly optimized clusters. This is why companies like Google, Meta, and NVIDIA invest heavily in custom network fabrics.</p>
        </div>

        <h3>The Allreduce Bottleneck</h3>
        <p>The most critical collective operation is <code>Allreduce</code>â€”it's called at the end of every training iteration to synchronize gradients across all workers. For a model with 175 billion parameters (like GPT-3):</p>

        <div class="diagram">Training Iteration Timeline:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                          â”‚
â”‚  Forward Pass    Backward Pass    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ ALLREDUCE â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    Update â”‚
â”‚  [Compute]       [Compute]        [NETWORK - CRITICAL PATH]     [Compute]â”‚
â”‚                                                                          â”‚
â”‚  ~200ms          ~300ms           ~500-2000ms (varies!)         ~50ms   â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

With 175B parameters Ã— 4 bytes (FP32) = 700GB gradient data per iteration
Even with FP16: 350GB must be synchronized across ALL GPUs</div>
        <p class="diagram-caption">Figure 1: Training iteration breakdown showing Allreduce as potential bottleneck</p>
    </section>

    <!-- Understanding Collective Operations -->
    <section>
        <h2>Understanding MPI Collective Operations</h2>

        <p>MPI (Message Passing Interface) defines standardized communication primitives that all distributed training frameworks implement. Understanding these operations is essential for network capacity planning and troubleshooting.</p>

        <h3>Allreduce: The Critical Path</h3>
        <p>Allreduce combines data from all processes and distributes the result to all processes. In AI training, this synchronizes gradients across all GPUs.</p>

        <div class="diagram">ALLREDUCE Operation (Ring Algorithm):

Initial State:           After Allreduce:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”                â”Œâ”€â”€â”€â”€â”€â”€â”€â”
â”‚GPU 0  â”‚ [A]            â”‚GPU 0  â”‚ [A+B+C+D]
â””â”€â”€â”€â”¬â”€â”€â”€â”˜                â””â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â”                â”Œâ”€â”€â”€â”€â”€â”€â”€â”
â”‚GPU 1  â”‚ [B]    â•â•â•â–º    â”‚GPU 1  â”‚ [A+B+C+D]
â””â”€â”€â”€â”¬â”€â”€â”€â”˜                â””â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â”                â”Œâ”€â”€â”€â”€â”€â”€â”€â”
â”‚GPU 2  â”‚ [C]            â”‚GPU 2  â”‚ [A+B+C+D]
â””â”€â”€â”€â”¬â”€â”€â”€â”˜                â””â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â”                â”Œâ”€â”€â”€â”€â”€â”€â”€â”
â”‚GPU 3  â”‚ [D]            â”‚GPU 3  â”‚ [A+B+C+D]
â””â”€â”€â”€â”€â”€â”€â”€â”˜                â””â”€â”€â”€â”€â”€â”€â”€â”˜

Each GPU contributes its gradients â†’ All GPUs receive the sum</div>
        <p class="diagram-caption">Figure 2: Allreduce aggregates and distributes data to all participants</p>

        <div class="info-box technical">
            <h4>ğŸ”§ Technical Deep Dive: Ring Allreduce</h4>
            <p>The Ring Allreduce algorithm is bandwidth-optimal for large messages. For N nodes with message size M:</p>
            <ul>
                <li><strong>Data transferred per node:</strong> 2M Ã— (N-1)/N â‰ˆ 2M for large N</li>
                <li><strong>Steps required:</strong> 2(N-1) communication steps</li>
                <li><strong>Bandwidth utilization:</strong> Approaches 100% of bidirectional link capacity</li>
            </ul>
            <p>This is why high-bandwidth, low-latency networks are criticalâ€”Allreduce performance scales directly with network performance.</p>
        </div>

        <h3>All Collective Operations Explained</h3>

        <div class="table-wrapper">
            <table>
                <tr>
                    <th>Operation</th>
                    <th>Description</th>
                    <th>AI Training Use Case</th>
                    <th>Frequency</th>
                    <th>Network Impact</th>
                </tr>
                <tr>
                    <td><strong>Allreduce</strong></td>
                    <td>Reduce + Broadcast: Combine values from all nodes, result to all</td>
                    <td>Gradient synchronization in data parallelism</td>
                    <td>Every iteration</td>
                    <td>ğŸ”´ Critical</td>
                </tr>
                <tr>
                    <td><strong>Broadcast</strong></td>
                    <td>One-to-all: Send data from one node to all others</td>
                    <td>Model weight initialization, hyperparameter distribution</td>
                    <td>Start of training, checkpoints</td>
                    <td>ğŸŸ¡ Moderate</td>
                </tr>
                <tr>
                    <td><strong>Allgather</strong></td>
                    <td>Gather + Broadcast: Collect data from all nodes, result to all</td>
                    <td>Batch normalization statistics, ZeRO optimizer stage 3</td>
                    <td>Per layer (BatchNorm)</td>
                    <td>ğŸŸ¡ Moderate</td>
                </tr>
                <tr>
                    <td><strong>Reduce-Scatter</strong></td>
                    <td>Reduce + Scatter: Combine and distribute chunks</td>
                    <td>ZeRO optimizer stage 2, gradient sharding</td>
                    <td>Every iteration (with ZeRO)</td>
                    <td>ğŸ”´ Critical</td>
                </tr>
                <tr>
                    <td><strong>All-to-All</strong></td>
                    <td>Personalized exchange: Each node sends unique data to each other</td>
                    <td>Mixture of Experts (MoE) routing, tensor parallelism</td>
                    <td>Per MoE layer</td>
                    <td>ğŸ”´ Critical for MoE</td>
                </tr>
                <tr>
                    <td><strong>Reduce</strong></td>
                    <td>Many-to-one: Combine values from all nodes to one root</td>
                    <td>Loss aggregation for logging</td>
                    <td>Every N iterations</td>
                    <td>ğŸŸ¢ Low</td>
                </tr>
            </table>
        </div>

        <h3>Visual Guide to Collective Operations</h3>
        <div class="diagram">â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     MPI COLLECTIVE OPERATIONS PATTERNS                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                  â”‚
â”‚  BROADCAST (One-to-All)              REDUCE (All-to-One)                        â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                          â”‚
â”‚                                                                                  â”‚
â”‚      Root â”€â”€â”¬â”€â”€â–º Node1                  Node0 â”€â”€â”                               â”‚
â”‚             â”œâ”€â”€â–º Node2                  Node1 â”€â”€â”¼â”€â”€â–º SUM â”€â”€â–º Root               â”‚
â”‚             â”œâ”€â”€â–º Node3                  Node2 â”€â”€â”¤                               â”‚
â”‚             â””â”€â”€â–º Node4                  Node3 â”€â”€â”˜                               â”‚
â”‚                                                                                  â”‚
â”‚  ALLREDUCE (All-to-All Reduce)       ALLGATHER (Gather + Broadcast)             â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•       â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•              â”‚
â”‚                                                                                  â”‚
â”‚      Node0 â”€â”€â”                          Node0 [A] â”€â”€â”                           â”‚
â”‚      Node1 â”€â”€â”¼â”€â”€â–º SUM â”€â”€â–º All           Node1 [B] â”€â”€â”¼â”€â”€â–º [A,B,C,D] to All      â”‚
â”‚      Node2 â”€â”€â”¤       Nodes              Node2 [C] â”€â”€â”¤                           â”‚
â”‚      Node3 â”€â”€â”˜                          Node3 [D] â”€â”€â”˜                           â”‚
â”‚                                                                                  â”‚
â”‚  SCATTER (One-to-All Chunks)         ALL-TO-ALL (Personalized Exchange)         â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•          â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•          â”‚
â”‚                                                                                  â”‚
â”‚      Root â”€â”€â”¬â”€â”€â–º [A] Node0              Each node sends unique                  â”‚
â”‚      [ABCD] â”œâ”€â”€â–º [B] Node1              data to every other node               â”‚
â”‚             â”œâ”€â”€â–º [C] Node2                                                      â”‚
â”‚             â””â”€â”€â–º [D] Node3              Critical for MoE models!                â”‚
â”‚                                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜</div>
        <p class="diagram-caption">Figure 3: Visual patterns of all major MPI collective operations</p>
    </section>

    <!-- Test Environment -->
    <section>
        <h2>Test Environment & Methodology</h2>

        <h3>Cluster Architecture</h3>
        <div class="diagram">â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         8-NODE RDMA AI CLUSTER                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                  â”‚
â”‚                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                â”‚
â”‚                          â”‚   Cisco Nexus 9K    â”‚                                â”‚
â”‚                          â”‚   100G Switch       â”‚                                â”‚
â”‚                          â”‚   PFC + ECN Enabled â”‚                                â”‚
â”‚                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                â”‚
â”‚                                     â”‚                                           â”‚
â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚           â”‚         â”‚         â”‚     â”‚     â”‚         â”‚         â”‚                 â”‚
â”‚       â”Œâ”€â”€â”€â–¼â”€â”€â”€â” â”Œâ”€â”€â”€â–¼â”€â”€â”€â” â”Œâ”€â”€â”€â–¼â”€â”€â”€â” â”‚ â”Œâ”€â”€â”€â–¼â”€â”€â”€â” â”Œâ”€â”€â”€â–¼â”€â”€â”€â” â”Œâ”€â”€â”€â–¼â”€â”€â”€â”           â”‚
â”‚       â”‚Node 1 â”‚ â”‚Node 2 â”‚ â”‚Node 3 â”‚ â”‚ â”‚Node 5 â”‚ â”‚Node 6 â”‚ â”‚Node 7 â”‚           â”‚
â”‚       â”‚.11.152â”‚ â”‚.11.153â”‚ â”‚.11.154â”‚ â”‚ â”‚.11.107â”‚ â”‚.12.51 â”‚ â”‚.20.150â”‚           â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                               â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚                               â”‚  Node 4   â”‚                 â”‚Node 8 â”‚           â”‚
â”‚                               â”‚  .11.155  â”‚                 â”‚.30.94 â”‚           â”‚
â”‚                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                                                                                  â”‚
â”‚  Network: 25Gbps RoCEv2 per node                                                â”‚
â”‚  NIC: Mellanox ConnectX-4 Lx (VMware PVRDMA)                                    â”‚
â”‚  Transport: UCX with UD verbs                                                    â”‚
â”‚  Lossless: PFC enabled on Priority 3, ECN thresholds configured                 â”‚
â”‚                                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜</div>
        <p class="diagram-caption">Figure 4: Test cluster topology with 8 RDMA-enabled nodes</p>

        <h3>Hardware Specifications</h3>
        <div class="table-wrapper">
            <table>
                <tr>
                    <th>Component</th>
                    <th>Specification</th>
                    <th>Notes</th>
                </tr>
                <tr>
                    <td>Servers</td>
                    <td>8x Ubuntu 22.04 VMs on ESXi</td>
                    <td>PVRDMA enabled for RDMA passthrough</td>
                </tr>
                <tr>
                    <td>Network Interface</td>
                    <td>Mellanox ConnectX-4 Lx 25GbE</td>
                    <td>RoCEv2 capable, ECN support</td>
                </tr>
                <tr>
                    <td>Switch</td>
                    <td>Cisco Nexus 9000</td>
                    <td>PFC, ECN, deep buffers enabled</td>
                </tr>
                <tr>
                    <td>MPI Implementation</td>
                    <td>OpenMPI 4.1.x with UCX</td>
                    <td>Optimized for RDMA transports</td>
                </tr>
                <tr>
                    <td>Benchmark Suite</td>
                    <td>OSU Micro-Benchmarks 7.x</td>
                    <td>Industry standard for MPI performance</td>
                </tr>
            </table>
        </div>

        <h3>Network Configuration for Lossless Operation</h3>
        <p>AI training requires lossless networking because TCP retransmissions introduce unacceptable latency variance. Our configuration uses:</p>

        <pre><code><span class="code-comment"># UCX Transport Configuration</span>
<span class="code-keyword">export</span> UCX_TLS=ud_verbs,self,sm
<span class="code-keyword">export</span> UCX_NET_DEVICES=all

<span class="code-comment"># OpenMPI with UCX backend (bypasses TCP entirely)</span>
mpirun --hostfile hostfile_rdma -np 8 \
    -x UCX_TLS -x UCX_NET_DEVICES \
    --mca pml ucx \
    --mca btl ^openib,tcp \
    $BENCHMARK</code></pre>

        <div class="info-box concept">
            <h4>ğŸ’¡ Why UCX with UD Verbs?</h4>
            <p><strong>UCX (Unified Communication X)</strong> is a high-performance communication library that provides:</p>
            <ul>
                <li><strong>RDMA support:</strong> Zero-copy data transfers, kernel bypass</li>
                <li><strong>Protocol selection:</strong> Automatically chooses optimal transport</li>
                <li><strong>UD (Unreliable Datagram) verbs:</strong> Lower overhead than RC (Reliable Connected) for collective operations</li>
            </ul>
            <p>UD verbs combined with PFC provide effectively lossless operation with lower connection overhead than RC, making it ideal for many-to-many communication patterns.</p>
        </div>
    </section>

    <!-- Benchmark Results -->
    <section>
        <h2>Benchmark Results & Analysis</h2>

        <h3>Allreduce Performance Across Message Sizes</h3>
        <p>Allreduce performance varies dramatically with message size due to different algorithmic strategies:</p>

        <div class="table-wrapper">
            <table>
                <tr>
                    <th>Message Size</th>
                    <th>Latency</th>
                    <th>Effective Bandwidth</th>
                    <th>Algorithm Used</th>
                    <th>AI Training Context</th>
                </tr>
                <tr>
                    <td>1 KB</td>
                    <td><strong>64.9 Î¼s</strong></td>
                    <td>0.12 Gbps</td>
                    <td>Recursive Doubling</td>
                    <td>Small tensors, scalar metrics</td>
                </tr>
                <tr>
                    <td>64 KB</td>
                    <td><strong>484 Î¼s</strong></td>
                    <td>1.06 Gbps</td>
                    <td>Ring / Recursive Halving</td>
                    <td>Small layer gradients</td>
                </tr>
                <tr>
                    <td>1 MB</td>
                    <td><strong>10.6 ms</strong></td>
                    <td>0.75 Gbps</td>
                    <td>Ring Allreduce</td>
                    <td>Medium layer gradients</td>
                </tr>
                <tr>
                    <td>4 MB</td>
                    <td><strong>38.9 ms</strong></td>
                    <td>0.82 Gbps</td>
                    <td>Ring Allreduce</td>
                    <td>Large layer gradients, typical for transformers</td>
                </tr>
                <tr>
                    <td>16 MB</td>
                    <td><strong>152 ms</strong></td>
                    <td>0.84 Gbps</td>
                    <td>Ring Allreduce</td>
                    <td>Embedding layers, very large tensors</td>
                </tr>
            </table>
        </div>

        <div class="info-box important">
            <h4>âš ï¸ Key Observation: Latency-Bandwidth Tradeoff</h4>
            <p>Notice how small messages (1KB) have very low latency but poor bandwidth utilization, while large messages (16MB) maximize bandwidth but have high absolute latency. This is why modern frameworks use <strong>gradient bucketing</strong>â€”combining small gradients into larger messages to improve efficiency.</p>
        </div>

        <h3>Complete Collective Operations Benchmark</h3>
        <div class="table-wrapper">
            <table>
                <tr>
                    <th>Operation</th>
                    <th>1 MB Latency</th>
                    <th>4 MB Latency</th>
                    <th>Target (Production)</th>
                    <th>Status</th>
                </tr>
                <tr>
                    <td>Allreduce</td>
                    <td>10.6 ms</td>
                    <td>38.9 ms</td>
                    <td>&lt; 50ms</td>
                    <td style="color: var(--success);">âœ“ PASS</td>
                </tr>
                <tr>
                    <td>Broadcast</td>
                    <td>5.87 ms</td>
                    <td>25.4 ms</td>
                    <td>&lt; 30ms</td>
                    <td style="color: var(--success);">âœ“ PASS</td>
                </tr>
                <tr>
                    <td>Reduce</td>
                    <td>5.85 ms</td>
                    <td>24.1 ms</td>
                    <td>&lt; 30ms</td>
                    <td style="color: var(--success);">âœ“ PASS</td>
                </tr>
                <tr>
                    <td>Allgather</td>
                    <td>6.30 ms</td>
                    <td>27.8 ms</td>
                    <td>&lt; 35ms</td>
                    <td style="color: var(--success);">âœ“ PASS</td>
                </tr>
                <tr>
                    <td>All-to-All</td>
                    <td>73.0 ms</td>
                    <td>285 ms</td>
                    <td>&lt; 100ms (1MB)</td>
                    <td style="color: var(--success);">âœ“ PASS</td>
                </tr>
            </table>
        </div>

        <h3>Traffic Generation Analysis</h3>
        <p>Understanding actual network load is critical for capacity planning:</p>

        <div class="diagram">NETWORK TRAFFIC DURING ALLREDUCE (Ring Algorithm)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

8 Nodes, 4MB message per node = 32MB total gradient data

Ring Allreduce executes in 2 phases:
  Phase 1: Reduce-Scatter (7 steps for 8 nodes)
  Phase 2: Allgather (7 steps for 8 nodes)

Per-node traffic:
  â””â”€â”€ Each node sends: 4MB Ã— (N-1)/N Ã— 2 â‰ˆ 7MB
  â””â”€â”€ Each node receives: 4MB Ã— (N-1)/N Ã— 2 â‰ˆ 7MB
  â””â”€â”€ Total per-node bidirectional: ~14MB

Cluster-wide traffic:
  â””â”€â”€ Total data moved: 8 nodes Ã— 14MB = 112MB per Allreduce
  â””â”€â”€ At 38.9ms latency: ~23 Gbps aggregate bandwidth utilized

For continuous training at 100 iterations/second:
  â””â”€â”€ Network load: 112MB Ã— 100 = 11.2 GB/second sustained
  â””â”€â”€ This is why 100Gbps+ networks are standard for AI clusters!</div>
        <p class="diagram-caption">Figure 5: Network traffic analysis for Allreduce operations</p>
    </section>

    <!-- Real-World Implications -->
    <section>
        <h2>Real-World Training Implications</h2>

        <h3>Calculating Training Throughput Impact</h3>
        <p>Let's calculate how network performance affects actual training speed for a GPT-3 scale model:</p>

        <div class="info-box technical">
            <h4>ğŸ§® Example: GPT-3 175B Training Analysis</h4>
            <p><strong>Model:</strong> 175 billion parameters</p>
            <p><strong>Gradient size:</strong> 175B Ã— 2 bytes (FP16) = 350GB per iteration</p>
            <p><strong>Cluster:</strong> 1024 GPUs across 128 nodes</p>
            <p><strong>Network:</strong> 200Gbps per node (8Ã— 25Gbps NICs with NVLink for intra-node)</p>

            <p><strong>Allreduce time calculation:</strong></p>
            <ul>
                <li>Per-node gradient: 350GB / 1024 = 341MB</li>
                <li>Ring Allreduce data per node: 341MB Ã— 2 = 682MB</li>
                <li>At 200Gbps (25GB/s): 682MB / 25GB/s = 27ms (theoretical minimum)</li>
                <li>With protocol overhead (~40%): ~38ms actual</li>
            </ul>

            <p><strong>Impact on training:</strong></p>
            <ul>
                <li>If compute time is 200ms per iteration</li>
                <li>Communication time: 38ms (16% overhead)</li>
                <li>Total iteration: 238ms â†’ 4.2 iterations/second</li>
                <li><strong>16% of training time spent on network communication!</strong></li>
            </ul>
        </div>

        <h3>Comparison: Our Cluster vs. Production Requirements</h3>
        <div class="table-wrapper">
            <table>
                <tr>
                    <th>Metric</th>
                    <th>Our 8-Node Cluster</th>
                    <th>Production AI Cluster</th>
                    <th>Scaling Factor</th>
                </tr>
                <tr>
                    <td>Node Count</td>
                    <td>8</td>
                    <td>1,000+</td>
                    <td>125x</td>
                </tr>
                <tr>
                    <td>Per-Node Bandwidth</td>
                    <td>25 Gbps</td>
                    <td>400-800 Gbps</td>
                    <td>16-32x</td>
                </tr>
                <tr>
                    <td>Allreduce Latency (4MB)</td>
                    <td>38.9 ms</td>
                    <td>&lt; 10ms (target)</td>
                    <td>4x improvement needed</td>
                </tr>
                <tr>
                    <td>Network Topology</td>
                    <td>Single switch</td>
                    <td>Multi-tier fat-tree / Dragonfly</td>
                    <td>Complex routing</td>
                </tr>
            </table>
        </div>

        <h3>Network Design Recommendations</h3>
        <p>Based on our benchmarking experience, here are key recommendations for AI cluster networks:</p>

        <div class="key-takeaway">
            <h4>ğŸ¯ Network Design Principles for AI Training</h4>
            <ul>
                <li><strong>Provision for 2x expected bandwidth:</strong> Collective operations create bursty, synchronized traffic patterns</li>
                <li><strong>Minimize hop count:</strong> Each switch hop adds latency; fat-tree topologies should be shallow</li>
                <li><strong>Enable lossless Ethernet:</strong> PFC prevents drops; ECN prevents PFC storms</li>
                <li><strong>Use RDMA everywhere:</strong> TCP overhead is unacceptable for large-scale training</li>
                <li><strong>Monitor collective operation latency:</strong> Traditional metrics (throughput, drops) don't capture AI workload health</li>
                <li><strong>Plan for All-to-All:</strong> MoE models require high bisection bandwidth, not just ring bandwidth</li>
            </ul>
        </div>
    </section>

    <!-- Congestion Control -->
    <section>
        <h2>Congestion Control in Action</h2>

        <p>During our stress tests, we observed active congestion control, proving the lossless network is functioning correctly:</p>

        <div class="stats-grid">
            <div class="stat-card">
                <span class="value">200-600</span>
                <span class="label">ECN marks/second</span>
            </div>
            <div class="stat-card">
                <span class="value">0</span>
                <span class="label">Packet drops</span>
            </div>
            <div class="stat-card">
                <span class="value">Active</span>
                <span class="label">PFC on switch</span>
            </div>
            <div class="stat-card">
                <span class="value">Multi-Gbps</span>
                <span class="label">Sustained throughput</span>
            </div>
        </div>

        <h3>Why ECN Marks Are Good News</h3>
        <p>Many engineers see ECN marks as a problemâ€”they're actually the solution working correctly:</p>

        <div class="diagram">DCQCN Congestion Control During MPI Stress Test
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Timeline of a congestion event:

T=0ms:    All 8 nodes start Allreduce simultaneously
          â”‚
          â–¼
T=0.1ms:  Switch queue fills rapidly (synchronized traffic)
          Queue depth: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 80% capacity
          â”‚
          â–¼
T=0.2ms:  ECN threshold exceeded â†’ Switch marks packets with CE bit
          Action: ECN marking begins (NOT dropping!)
          â”‚
          â–¼
T=0.5ms:  Receiver NICs detect CE marks â†’ Generate CNP packets
          CNP sent back to senders with DSCP 48 (high priority)
          â”‚
          â–¼
T=1.0ms:  Sender NICs receive CNP â†’ DCQCN rate limiter activates
          Transmission rate reduced by 50%
          â”‚
          â–¼
T=5.0ms:  Queue drains â†’ ECN marking stops
          Rate gradually increases back to line rate
          â”‚
          â–¼
          RESULT: Zero packet loss, brief throughput reduction
          Training continues uninterrupted!</div>
        <p class="diagram-caption">Figure 6: DCQCN congestion control timeline during MPI stress test</p>

        <p>This is the <strong>fundamental difference</strong> between TCP-based and RDMA-based AI training:</p>
        <ul>
            <li><strong>TCP:</strong> Drops packets â†’ Retransmissions â†’ 1000x latency spike â†’ Training stalls</li>
            <li><strong>RDMA + DCQCN:</strong> Marks packets â†’ Rate reduction â†’ 2x latency briefly â†’ Training continues</li>
        </ul>
    </section>

    <!-- Tools and Commands -->
    <section>
        <h2>Benchmarking Tools & Commands</h2>

        <h3>Running OSU Micro-Benchmarks</h3>
        <pre><code><span class="code-comment"># Install OSU Micro-Benchmarks</span>
wget https://mvapich.cse.ohio-state.edu/download/mvapich/osu-micro-benchmarks-7.3.tar.gz
tar -xzf osu-micro-benchmarks-7.3.tar.gz
cd osu-micro-benchmarks-7.3
./configure CC=mpicc CXX=mpicxx --prefix=/usr/local
make && make install

<span class="code-comment"># Run Allreduce benchmark across all 8 nodes</span>
mpirun --hostfile ~/hostfile_rdma -np 8 \
    -x UCX_TLS=ud_verbs,self,sm \
    -x UCX_NET_DEVICES=all \
    --mca pml ucx --mca btl ^openib,tcp \
    /usr/local/libexec/osu-micro-benchmarks/mpi/collective/osu_allreduce

<span class="code-comment"># Benchmark specific message sizes</span>
mpirun ... osu_allreduce -m 1048576:4194304  <span class="code-comment"># 1MB to 4MB</span>

<span class="code-comment"># Run multiple iterations for stable results</span>
mpirun ... osu_allreduce -i 1000 -m 4194304  <span class="code-comment"># 1000 iterations, 4MB</span></code></pre>

        <h3>MPI Test Controller (Custom Tool)</h3>
        <pre><code><span class="code-comment"># Our custom controller for continuous testing</span>
./mpi_test_controller.py once     <span class="code-comment"># Single benchmark run</span>
./mpi_test_controller.py start    <span class="code-comment"># Continuous monitoring mode</span>
./mpi_test_controller.py status   <span class="code-comment"># Check test status</span>
./mpi_test_controller.py stop     <span class="code-comment"># Stop all tests</span>

<span class="code-comment"># Bandwidth stress test (saturates network)</span>
./mpi_bandwidth_stress.py start   <span class="code-comment"># Generate maximum traffic</span>
./mpi_bandwidth_stress.py status  <span class="code-comment"># Monitor ECN/PFC activity</span></code></pre>

        <h3>Monitoring Network During Tests</h3>
        <pre><code><span class="code-comment"># Watch ECN counters on server (run during test)</span>
watch -n 1 "rdma statistic show | grep -E 'ecn|cnp'"

<span class="code-comment"># Watch PFC counters on Cisco Nexus switch</span>
show interface ethernet 1/1 priority-flow-control
show queuing interface ethernet 1/1

<span class="code-comment"># Capture RoCEv2 traffic for analysis</span>
tcpdump -i ens192 -w mpi_test.pcap udp port 4791</code></pre>
    </section>

    <!-- Conclusion -->
    <section>
        <h2>Conclusions & Future Work</h2>

        <h3>Key Findings</h3>
        <ol>
            <li><strong>Allreduce dominates training time:</strong> Network optimization should focus primarily on collective operation latency, not just raw throughput.</li>
            <li><strong>Message size matters:</strong> Small messages are latency-bound; large messages are bandwidth-bound. Gradient bucketing helps bridge this gap.</li>
            <li><strong>Lossless networking is non-negotiable:</strong> ECN + PFC provide the predictable latency AI training requires.</li>
            <li><strong>RDMA is essential at scale:</strong> TCP overhead becomes unacceptable for synchronized collective operations.</li>
            <li><strong>All-to-All is the next frontier:</strong> Mixture of Experts models are driving demand for higher bisection bandwidth.</li>
        </ol>

        <h3>Future Enhancements</h3>
        <ul>
            <li>Add NVIDIA GPU nodes with NCCL benchmarking</li>
            <li>Implement gradient compression analysis</li>
            <li>Test with actual PyTorch distributed training workloads</li>
            <li>Compare in-network aggregation (NVIDIA SHARP) performance</li>
            <li>Evaluate next-generation 400GbE performance</li>
        </ul>

        <div class="info-box success">
            <h4>âœ… Project Success Criteria Met</h4>
            <ul>
                <li>All collective operations within production targets</li>
                <li>Zero packet loss during stress tests</li>
                <li>Active congestion control verified (ECN/CNP working)</li>
                <li>Reproducible benchmark methodology established</li>
                <li>Foundation laid for GPU cluster expansion</li>
            </ul>
        </div>
    </section>

    <!-- References -->
    <section>
        <h2>References & Further Reading</h2>
        <ul>
            <li><a href="https://www.mpi-forum.org/docs/" target="_blank">MPI Forum - Official MPI Specification</a></li>
            <li><a href="https://developer.nvidia.com/nccl" target="_blank">NVIDIA NCCL - Optimized Collective Communications</a></li>
            <li><a href="https://openucx.org/" target="_blank">UCX - Unified Communication X Framework</a></li>
            <li><a href="https://mvapich.cse.ohio-state.edu/benchmarks/" target="_blank">OSU Micro-Benchmarks</a></li>
            <li><a href="https://arxiv.org/abs/1802.05799" target="_blank">Horovod: Fast and Easy Distributed Deep Learning (Uber)</a></li>
            <li><a href="https://conferences.sigcomm.org/sigcomm/2015/pdf/papers/p523.pdf" target="_blank">DCQCN Paper (SIGCOMM 2015)</a></li>
        </ul>
    </section>

    <!-- Author Section -->
    <div class="author-section">
        <div class="author-info">
            <h3>Eniz Aksoy</h3>
            <p class="title">CCIE Routing & Switching #23970 | Senior Network Architect | AI/ML Infrastructure</p>
            <p>Specializing in high-performance networking for distributed AI training, with expertise in RDMA, lossless Ethernet, and data center fabrics. Currently exploring opportunities in AI infrastructure at scale.</p>
            <div class="author-links">
                <a href="https://github.com/Enizaksoy/mpi-ai-cluster-benchmark" target="_blank">View GitHub Repo</a>
                <a href="https://linkedin.com/in/enizaksoy" target="_blank">Connect on LinkedIn</a>
                <a href="../index.html">View All Projects</a>
            </div>
        </div>
    </div>

</main>

<!-- Footer -->
<footer>
    <p>&copy; 2026 Eniz Aksoy. CCIE #23970. All rights reserved.</p>
    <p>Analysis based on benchmarks from 8-node RDMA AI cluster | <a href="../index.html">Back to Portfolio</a></p>
</footer>

</body>
</html>
